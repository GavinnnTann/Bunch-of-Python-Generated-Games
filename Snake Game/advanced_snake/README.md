# Advanced Snake Game with Reinforcement Learning# Advanced Snake Game - Clean Project Structure



A comprehensive Snake game implementation featuring multiple AI algorithms, deep reinforcement learning with curriculum learning, and advanced training visualization.## ğŸ“ Essential Files



---### Core Game Components

- **`constants.py`** - Game configuration and hyperparameters

## ğŸ® Features- **`game_engine.py`** - Snake game logic and mechanics

- **`ui.py`** - User interface components

### Game Modes

- **Manual Play** - Classic Snake with WASD controls### Algorithm Implementations

- **A* Algorithm** - Intelligent pathfinding- **`algorithms.py`** - Traditional algorithms (A*, BFS, Hamiltonian)

- **Dijkstra Algorithm** - Guaranteed shortest path- **`q_learning.py`** - Q-Learning (Tabular) agent

- **Q-Learning** - Tabular reinforcement learning- **`advanced_dqn.py`** - Deep Q-Network agent

- **Enhanced DQN** - Deep Q-Network with curriculum learning- **`enhanced_dqn.py`** - Enhanced DQN with curriculum learning

- **`gpu_utils.py`** - GPU acceleration utilities

### Enhanced DQN Capabilities

- âœ¨ **Curriculum Learning** - 5 progressive difficulty stages### Main Entry Points

- âœ¨ **Advanced Architecture** - Double DQN + Dueling + Prioritized Replay- **`main.py`** - Main game interface (play/watch AI)

- âœ¨ **Real-time Visualization** - Comprehensive training UI- **`training_ui.py`** - **PRIMARY TRAINING TOOL** - Comprehensive training interface with:

- âœ¨ **Learning Momentum** - Gradient indicators across 3 time scales  - Model selection (Q-Learning, Original DQN, Enhanced DQN)

- âœ¨ **Stuck Detection** - Automatic exploration boosts (configurable)  - Real-time training graphs

- âœ¨ **GPU Acceleration** - CUDA support for faster training  - Hyperparameter controls

- âœ¨ **Performance Optimized** - 90% faster UI updates  - Model management



---### Training Scripts (Called by training_ui.py)

- **`train_qlearning.py`** - Q-Learning training backend

## ğŸš€ Quick Start- **`train_enhanced.py`** - Enhanced DQN training backend



### Installation### Model Storage

- **`models/`** - Saved models and training statistics

```bash  - `snake_qlearning_model.pkl` - Q-Learning model

# Install dependencies  - `snake_enhanced_dqn*.pth` - Enhanced DQN models

pip install torch numpy matplotlib pygame  - `*_history.json` - Training history files

  - `qlearning_training_stats.json` - Q-Learning stats

# Verify GPU support (optional)

python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"### Documentation

```- **`QUICK_REFERENCE.md`** - Quick reference guide



### Train Your First Agent## ğŸ—‘ï¸ Removed Non-Essential Files



**Option 1: Training UI (Recommended)**### Debug/Test Scripts (Deleted)

```bash- âŒ `check_cuda.py` - One-time CUDA setup check

python training_ui.py- âŒ `debug_model.py` - Model debugging tool

```- âŒ `test_batch_size.py` - GPU memory testing

Click "Start Training" and watch the visualization!- âŒ `test_enhanced.py` - Enhanced DQN testing

- âŒ `demo_new_graphs.py` - Graph visualization demo

**Option 2: Command Line**- âŒ `diagnose_stagnation.py` - Training analysis tool

```bash- âŒ `compare_training.py` - Model comparison tool

python train_enhanced.py --episodes 1000- âŒ `check_model_state.py` - Model state inspector

```

### Redundant Training Scripts (Deleted - Replaced by training_ui.py)

### Play with Trained Agent- âŒ `training.py` - Old training script

- âŒ `dqn_training.py` - Old DQN training

```bash- âŒ `headless_training.py` - Replaced by training UI

python main.py

# Select "Advanced DQN" â†’ Load Existing Model### Batch Files (Deleted)

```- âŒ `run_headless_training.bat`

- âŒ `run_training_ui.bat`

---

### Analysis Documentation (Deleted)

## ğŸ“Š Training UI Features- âŒ `OPTIMAL_HYPERPARAMETERS_ANALYSIS.md`

- âŒ `STAGE_2_ANALYSIS.md`

### Real-time Monitoring

- **Score Progression Graph** - Episode scores + 100-episode average### Old Model Checkpoints (Deleted)

- **Gradient Indicators** - Learning momentum visualization- âŒ `snake_dqn_model_ep*_interrupted_*.json` - Interrupted training files

  - Overall gradient (long-term progress)

  - Mid-term gradient (acceleration/deceleration)## ğŸš€ How to Use

  - Recent gradient (current momentum) - **MOST IMPORTANT**

- **Curriculum Markers** - Stage advancement annotations### Play the Game

- **Epsilon & Learning Rate Tracking** - Exploration/exploitation balance```bash

python main.py

### Gradient Color Coding```

- ğŸŸ¢ **Bright Green** (>+0.05 pts/ep): Strong improvement**Main Menu Options:**

- ğŸŸ¢ **Light Green** (+0.01 to +0.05): Slow improvement- Select game mode (Manual, A*, BFS, Hamiltonian, Q-Learning, Enhanced DQN)

- ğŸŸ¡ **Yellow** (-0.01 to +0.01): Stagnant (plateau)- Adjust speed

- ğŸŸ  **Orange** (-0.05 to -0.01): Weak decline- Browse and load trained models

- ğŸ”´ **Red** (<-0.05): Strong decline- Start playing!



### Stuck Detection Controls**Note:** Training options have been removed from main.py. Use `training_ui.py` for all training needs.

- â˜‘ Enable/Disable toggle

- Sensitivity slider (1-10 checks before boost)### Train Models (Recommended)

- Cooldown slider (50-500 episodes between boosts)```bash

- Boost amount slider (0.05-0.30 epsilon increase)python training_ui.py

- Min improvement threshold (2.0-15.0 points)```

The training UI provides:

---- Model type selection (Q-Learning, Original DQN, Enhanced DQN)

- Hyperparameter adjustment

## ğŸ“ Curriculum Learning System- Real-time performance graphs

- Model save/load management

Progressive 5-stage difficulty system that adapts learning parameters:- Training progress tracking



| Stage | Threshold | Description | Learning Rate | Epsilon Min |### Quick Training (Command Line)

|-------|-----------|-------------|---------------|-------------|```bash

| **0** | 0-20 avg | Beginner: Survival basics | 0.005 | 0.10 |# Q-Learning

| **1** | 20-50 avg | Novice: Consistent food collection | 0.003 | 0.05 |python train_qlearning.py --episodes 1000 --learning-rate 0.1 --batch-size 64

| **2** | 50-100 avg | Intermediate: Avoid traps | 0.002 | 0.04 |

| **3** | 100-200 avg | Advanced: Strategic planning | 0.001 | 0.02 |# Enhanced DQN

| **4** | 200+ avg | Expert: Score maximization | 0.0005 | 0.01 |python train_enhanced.py --episodes 2000 --batch-size 512 --save-interval 200

```

---

## ğŸ“Š Model Comparison

## ğŸ“š Documentation

| Model | State Space | Action Space | Training Time | Performance |

### Quick References|-------|-------------|--------------|---------------|-------------|

- **[QUICK_START_GUIDE.md](QUICK_START_GUIDE.md)** - Get started in 5 minutes| **Q-Learning** | 11 features (discrete) | 4 absolute (UP/DOWN/LEFT/RIGHT) | Fast (~50-100 eps/sec) | Excellent for Snake |

- **[COMPLETE_REFERENCE_GUIDE.md](COMPLETE_REFERENCE_GUIDE.md)** - Comprehensive documentation| **Original DQN** | 11 features | 3 relative (Turn Left/Straight/Right) | Medium (~10-30 eps/sec) | Moderate |

| **Enhanced DQN** | 34 features | 3 relative | Slower (~10-20 eps/sec) | Best with curriculum |

### Feature Guides

- **[GRADIENT_INDICATORS_GUIDE.md](GRADIENT_INDICATORS_GUIDE.md)** - Learning momentum explained## ğŸ’¡ Key Insights

- **[STUCK_DETECTION_TUNING_GUIDE.md](STUCK_DETECTION_TUNING_GUIDE.md)** - When and how to use boosts

- **[PERFORMANCE_IMPROVEMENTS.md](PERFORMANCE_IMPROVEMENTS.md)** - Optimization details### Why Q-Learning Outperforms DQN for Snake

1. **Absolute Actions**: Q-Learning uses direct spatial actions (UP/DOWN/LEFT/RIGHT)

---2. **Perfect Memory**: Tabular approach stores exact Q-values for each state

3. **Small State Space**: ~500-800 states for typical Snake gameplay

## ğŸ¯ Training Tips4. **Fast Training**: Reaches competence in ~1000 episodes



### When to Stop Training### When to Use Enhanced DQN

**Stop if:**- Larger, more complex environments

- âœ… Recent gradient Yellow for 300+ episodes- Need for generalization beyond seen states

- âœ… Max score hasn't improved in 500+ episodes- When state space is too large for tabular methods

- âœ… Average score plateaued (stable for 200+ episodes)- Continuous or high-dimensional state spaces



**Continue if:**## ğŸ”§ Project Cleanup Summary

- âœ… Recent gradient Green (improving)

- âœ… Mid-term > Overall (accelerating)**Removed**: 15+ non-essential files (debug scripts, redundant trainers, old docs)  

- âœ… Just advanced curriculum stage**Result**: Clean, maintainable codebase focused on core functionality  

**Benefit**: Easier navigation, reduced confusion, faster development

---

---

## ğŸ› ï¸ Command Reference

**Last Updated**: October 8, 2025  

```bash**Project**: Advanced Snake Game with RL Agents

# Train with UI (recommended)
python training_ui.py

# Train without UI
python train_enhanced.py --episodes 1000

# Play manually
python main.py â†’ Select "Manual"

# Watch trained agent
python main.py â†’ Select "Advanced DQN" â†’ Load Model

# Custom stuck detection
python train_enhanced.py --stuck-sensitivity 8 --stuck-cooldown 400

# Disable stuck detection
python train_enhanced.py --disable-stuck-detection
```

---

## ğŸ“Š Expected Results

### Typical Training Timeline
```
Episodes 1-50:     Stage 0 - Learn survival (gradient: bright green)
Episodes 50-200:   Stage 0â†’1 - Consistent food (gradient: green)
Episodes 200-500:  Stage 1â†’2 - Better strategy (gradient: light green)
Episodes 500-1000: Stage 2â†’3 - Advanced tactics (gradient: may turn yellow)
Episodes 1000+:    Fine-tuning (gradient: yellow = done)
```

### Final Performance
- **Stage 2 (50-100 avg):** Decent
- **Stage 3 (100-200 avg):** Good
- **Stage 4 (200+ avg):** Excellent!

---

## ğŸ“ Project Structure

```
advanced_snake/
â”œâ”€â”€ main.py                    # Game entry point
â”œâ”€â”€ training_ui.py             # Training UI (PRIMARY TOOL)
â”œâ”€â”€ enhanced_dqn.py            # Enhanced DQN with curriculum
â”œâ”€â”€ train_enhanced.py          # CLI training script
â”œâ”€â”€ constants.py               # All configuration
â”‚
â”œâ”€â”€ Documentation/
â”‚   â”œâ”€â”€ README.md              # This file
â”‚   â”œâ”€â”€ QUICK_START_GUIDE.md
â”‚   â”œâ”€â”€ COMPLETE_REFERENCE_GUIDE.md
â”‚   â””â”€â”€ [Feature guides...]
â”‚
â””â”€â”€ models/                    # Saved models
```

---

## ğŸš€ Quick Decision Guide

```
Want to play? 
  â†’ python main.py

Want to train?
  â†’ python training_ui.py (with UI)
  â†’ python train_enhanced.py (without UI, faster)

Want to understand?
  â†’ Read QUICK_START_GUIDE.md (5 minutes)
  â†’ Read COMPLETE_REFERENCE_GUIDE.md (comprehensive)

Want to know when to stop training?
  â†’ Watch Recent gradient (bottom colored box)
  â†’ Yellow for 200+ episodes = done
```

---

**Happy Training! ğŸğŸ®ğŸš€**

*Last Updated: October 10, 2025*
